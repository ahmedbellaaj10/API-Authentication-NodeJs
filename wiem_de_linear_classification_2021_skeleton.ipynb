{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/API-Authentication-NodeJs/blob/master/wiem_de_linear_classification_2021_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ewR7_sHJ00",
        "outputId": "44dc1ac5-acce-4c3e-8286-6d3fe9aa56fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Kn2s4LVCHL0J",
        "outputId": "7de451e9-5d16-40c5-db61-aa7cf8835046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-gvcty1w0\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-gvcty1w0\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=cfb77dbbc7707035f2aee739fce48a462db9ee0cf8486833b63d6f4de5b80889\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5n15jwpx/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "  Found existing installation: NVCCPlugin 0.0.1\n",
            "    Uninstalling NVCCPlugin-0.0.1:\n",
            "      Successfully uninstalled NVCCPlugin-0.0.1\n",
            "Successfully installed NVCCPlugin-0.0.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvcc_plugin"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade git+git://github.com/frehseg/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoKiUawdHMGn",
        "outputId": "c79adc7f-b223-4f4d-9096-ce5af6388371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-lgwhE1N5_7",
        "outputId": "a87bc6b1-595c-49fc-a021-4e8b63958677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting cuda_stuff.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iivrxLaYOYPh",
        "outputId": "49a3b686-5d27-4b60-8cad-557991627beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting cuda_stuff.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A97U902HMog4",
        "outputId": "d5c13214-4f1a-438d-c7af-76cfb580ef0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting fmatrix.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/* Access element (i,j) of matrix mat */\n",
        "#define getfm(mat,i,j) (mat.data[IDX2C(i,j,mat.rows)])\n",
        "\n",
        "\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "int fmatrix_size(fmatrix mat);\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        "void fmatrix_assert();\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_host);\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix points into the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "#endif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGwZ36ifWQ-d",
        "outputId": "906770c8-b78c-40e0-e7f1-5ea1321b3c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting fmatrix.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "     return fmatrix_elements(mat) * sizeof(mat.data[0]);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD7rmOBmWfsC",
        "outputId": "80402a84-3ec0-46f4-f648-d20421b7a4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting read_csv.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeedFsZ_WQx0",
        "outputId": "48cbf45e-5974-4b30-faca-f00c0b53a976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting read_csv.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex8ilQdYYroU",
        "outputId": "6152a463-82d7-49db-feb7-12285618d700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting preprocess_data.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaeUdw_KYaCx",
        "outputId": "ab127eda-4f5d-4e41-f649-3cc325aa8325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting preprocess_data.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_tmB-xbZKp",
        "outputId": "64989626-b9c8-42a9-eacc-e97c79024714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting classifier_math.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "#include \"cublas_v2.h\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "void mat_transp_mul(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C, int inv);\n",
        "/** Z = a*X^T*Y */\n",
        "void fmatrix_transp_mul(fmatrix Z,float a,fmatrix X,fmatrix Y);\n",
        "\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgXwgv6Bbo-I",
        "outputId": "f4b9eaed-3a1c-4a0a-d0a8-494c2b3bf99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting classifier_math.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_transp_mul_kernel(fmatrix Z,float a,fmatrix X,fmatrix Y) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / Z.rows;\n",
        "    int i = idx % Z.rows;\n",
        "    // printf(\"(%d,%d) \\n\",i,j);\n",
        "    if (i < Z.rows && j < Z.cols ){\n",
        "        getfm(Z,i,j) = 0.0;\n",
        "        for (int k = 0; k< X.rows ; ++k) {\n",
        "          // printf(\"%f + %f * %f * %f\\n\", getfm(Z,i,j), a,getfm(X,k,i),getfm(Y,k,j));\n",
        "          getfm(Z,i,j) += a*getfm(X,k,i)*getfm(Y,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void fmatrix_transp_mul(fmatrix Z,float a,fmatrix X,fmatrix Y) {\n",
        "    assert(Z.rows == X.cols);\n",
        "    assert(Z.cols == Y.cols);\n",
        "    assert(X.rows == Y.rows);\n",
        "\n",
        "    // printf(\"Z(%d,%d) elements %d \\n\",Z.rows,Z.cols,fmatrix_elements(Z));\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_transp_mul_kernel<<< blocksPerGrid, threadsPerBlock >>>(Z,a,X,Y);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "}\n",
        "\n",
        "void mat_transp_mul(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C, int inv){\n",
        "  /* TODO */\n",
        "  int m=d_A.rows;\n",
        "  int k=d_A.cols;\n",
        "  int n=d_B.cols;\n",
        "  if (inv == 0) {\n",
        "    m=d_A.cols;\n",
        "    k=d_A.rows;\n",
        "    n=d_B.cols;\n",
        "    }\n",
        "  else if (inv ==1) {\n",
        "    n=d_B.rows;\n",
        "  }\n",
        "\n",
        "  int lda=d_A.rows,ldb=d_B.rows,ldc=d_C.rows;\n",
        "\n",
        "  const float *alf = &alpha;\n",
        "  const float *bet= &beta;\n",
        "\n",
        "  // Create a handle for CUBLAS\n",
        "  cublasHandle_t handle;\n",
        "  cublasCreate(&handle);\n",
        "\n",
        "\n",
        "  //clock_t start, end;\n",
        "  //float cpu_time_used;\n",
        "  //start = clock();\n",
        "  // Do the actual multiplication\n",
        "  if (inv == 0)\n",
        "  {cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_N, m, n, k, alf, d_A.data, lda, d_B.data, ldb, bet, d_C.data, ldc);}\n",
        "  else\n",
        "  {\n",
        "      cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_T, m, n, k, alf, d_A.data, lda, d_B.data, ldb, bet, d_C.data, ldc);}\n",
        "\n",
        "  // Destroy the handle\n",
        "  cublasDestroy(handle);\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__\n",
        "void softmax_col_kernel(float *Z, float *P, int nb_ColZ, int nb_LigneZ) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    float s=0;\n",
        "\n",
        "\n",
        "    if (col < nb_ColZ){\n",
        "        for (int k=0; k<nb_LigneZ; k++){\n",
        "            s+=exp(Z[col*nb_LigneZ+k]);\n",
        "        }\n",
        "        for (int k=0; k<nb_LigneZ; k++) {\n",
        "            P[col*nb_LigneZ + k]=exp(Z[col*nb_LigneZ+k])/s;\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    int blocksize = 100;\n",
        "    dim3 dimBlock (blocksize);\n",
        "    dim3 dimGrid(ceil( Z.cols / (float)blocksize));\n",
        "    softmax_col_kernel <<< dimGrid, dimBlock >>>(Z.data, P.data, Z.cols, Z.rows);\n",
        "\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd7Vmzo72hpC",
        "outputId": "cbdb74cb-d1bc-434a-f35f-e18da82b9023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting evaluate_accuracy.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(k,j)*log(P(k,j))\n",
        " */\n",
        "float evaluate_logloss(fmatrix d_P,fmatrix d_Y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Z-9B4a2dwg",
        "outputId": "6c4ad381-96cb-49f5-9654-1d240ccc0b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting evaluate_accuracy.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5f) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "\n",
        "  // Z = W^T X\n",
        "  /* Multiplication on the device*/\n",
        "  //fmatrix_transp_mul(d_Z,1.0,d_W,d_X);\n",
        "\n",
        "  mat_transp_mul(1.0, d_W, d_X, 0.0, d_Z,0);\n",
        "  device_synchronize();\n",
        "  ////////////////////////////////\n",
        "  // compute Z = W^T X'\n",
        "  // --> each column of Z corresponds to one input\n",
        "  ////////////////////////////////\n",
        "  // For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  ////////////////////////////////\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "\n",
        "float evaluate_logloss(fmatrix h_P,fmatrix h_Y) {\n",
        "    assert(h_Y.cols == h_P.cols);\n",
        "    assert(h_Y.rows == h_P.rows);\n",
        "\n",
        "    float J = 0.0;\n",
        "\n",
        "    for (int i =0 ; i <h_P.cols; i++)\n",
        "    {\n",
        "    for (int k = 0 ; k < h_P.rows; k++)\n",
        "        {\n",
        "            J+=getfm(h_Y,k,i)* log(getfm(h_P,k,i));\n",
        "\n",
        "        }\n",
        "    }\n",
        "  J=-J/h_P.cols;\n",
        "  return J;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWO5p1NeHE9n",
        "outputId": "d56b5241-dafa-426e-86ac-2a296ee747e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting linear_classification.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "//#include \"sgemm.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train =12000; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test =5000; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 200; //10;\n",
        "    int periods = nb_iter; // reporting period\n",
        "    int batch_size = N/3; // N;\n",
        "    float learning_rate = 1e-7;\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(0.001,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "\n",
        " for (int m = 0; m < nb_iter; m++ )\n",
        "\n",
        " {    int batch_pointer = 0;\n",
        "     while (batch_pointer+batch_size <=N)\n",
        "     {\n",
        "        //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "        //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // compute Z = W^T X\n",
        "      // --> each column z of Z corresponds to one column x of X\n",
        "\n",
        "      ////////////////////////////////\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      fmatrix h_X=fmatrix_subcolumns(Xall,batch_pointer, batch_pointer+batch_size);\n",
        "      fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "      fmatrix h_Y = fmatrix_subcolumns(Yall,batch_pointer,  batch_pointer+batch_size);\n",
        "      fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "\n",
        "        mat_transp_mul(1.0, d_W, d_X, 0.0, d_Z, 0);\n",
        "        //printf(\"Z:\\n\"); fmatrix_device_print(d_Z);\n",
        "        //fmatrix d_Z2 = fmatrix_create_on_device(M,batch_size);\n",
        "        //fmatrix_transp_mul(d_Z2,1.0,d_W,d_X);\n",
        "       //printf(\"Z2:\\n\"); fmatrix_device_print(d_Z2);\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For each column z of Z, compute activation p(z);\n",
        "      // then update W\n",
        "      ////////////////////////////////\n",
        "\n",
        "      // compute softmax per column of Z and store in Z\n",
        "\n",
        "    ///////////////////////////////////\n",
        "        softmax_col(d_P, d_Z);\n",
        "        //printf(\"Z:\\n\"); fmatrix_device_print(d_Z);\n",
        "        //printf(\"P:\\n\"); fmatrix_device_print(d_P);\n",
        "        fmatrix h_P = fmatrix_copy_to_host(d_P);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      // evaluate logloss (for reporting only)\n",
        "\n",
        "    ///////////////////////////////////\n",
        "\n",
        "        J=evaluate_logloss(h_P, h_Y);\n",
        "        //printf (\"Jiiiiiii %f \\n\", J);\n",
        "    ///////////////////////////////////\n",
        "\n",
        "\n",
        "      // Q:=P-Y\n",
        "      // compute gradient G = 1/batch_size XQ^T\n",
        "      // ... possibly work with G here ...\n",
        "      // update weights W = W - learning_rate*G\n",
        "\n",
        "    ///////////////////////////////////\n",
        "        fmatrix h_Q = fmatrix_create_on_host(M,batch_size);\n",
        "        for (int i = 0 ; i < h_Q.rows; i++){\n",
        "            for (int j = 0 ; j<h_Q.cols; j++){\n",
        "                h_Q.data[IDX2C(i,j,h_Q.rows)]= getfm(h_P,i,j)-getfm(h_Y,i,j);\n",
        "      }\n",
        "    }\n",
        "\n",
        "\n",
        "        //fmatrix_print(h_Q);\n",
        "        fmatrix d_Q = fmatrix_copy_to_device(h_Q);\n",
        "\n",
        "\n",
        "        mat_transp_mul(1.0, d_X, d_Q, 0.0, d_G, 1);\n",
        "\n",
        "        fmatrix h_G = fmatrix_copy_to_host(d_G);\n",
        "        //printf(\"G:\\n\"); fmatrix_print(h_G);\n",
        "\n",
        "        fmatrix_data_to_device(h_G,d_G);\n",
        "        for (int i = 0 ; i < h_W.rows; i++){\n",
        "          for (int j = 0 ; j<h_W.cols; j++){\n",
        "              h_W.data[IDX2C(i,j,h_W.rows)]=getfm(h_W,i,j)- learning_rate/batch_size* getfm(h_G,i,j);\n",
        "          }\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "      fmatrix_data_to_device(h_W,d_W);\n",
        "      //printf(\"W_h:\\n\");fmatrix_print(h_W);\n",
        "\n",
        "\n",
        "\n",
        "      // For reporting, compute logloss and accuracy\n",
        "\n",
        "\n",
        "\n",
        "        float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "        printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",m,J, accuracy);\n",
        "        fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "\n",
        "batch_pointer+=batch_size;\n",
        "    }\n",
        "\n",
        " }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z52xd0NMRKXb",
        "outputId": "03a59c44-e2f3-4f98-d4e9-7d352a0d18ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_classification.cu(80): warning: variable \"periods\" was declared but never referenced\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvcc -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV_vFkIT7fV4",
        "outputId": "23366c3a-87fe-4c01-b4fe-633357cc647d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t-114.58\t-114.59\t-114.59\t-114.6\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t33.61\t34.83\t33.61\t34.83\t\n",
            "15\t19\t17\t14\t20\t29\t25\t41\t34\t46\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t2907\t812\t4789\t1497\t\n",
            "1283\t1901\t174\t337\t326\t236\t680\t168\t1175\t309\t\n",
            "1015\t1129\t333\t515\t624\t671\t1841\t375\t3134\t787\t\n",
            "472\t463\t117\t226\t262\t239\t633\t158\t1056\t271\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t2.6768\t1.7083\t2.1782\t2.1908\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.660200\n",
            "iter: 0, logloss: 0.573496, accuracy: 0.660000\n",
            "iter: 0, logloss: 0.629248, accuracy: 0.660200\n",
            "iter: 0, logloss: 0.583235, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.556888, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.625339, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.577853, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.552306, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.621040, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.574950, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.548659, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.616440, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.572572, accuracy: 0.660400\n",
            "iter: 4, logloss: 0.545293, accuracy: 0.660200\n",
            "iter: 4, logloss: 0.611906, accuracy: 0.660400\n",
            "iter: 4, logloss: 0.570405, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.542107, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.607553, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.568372, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.539075, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.603399, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.566449, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.536184, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.599448, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.564620, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.533427, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.595688, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.562881, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.530795, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.592110, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.561225, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.528283, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.588706, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.559651, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.525887, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.585465, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.558147, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.523599, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.582378, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.556714, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.521414, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.579440, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.555348, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.519329, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.576639, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.554043, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.517339, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.573971, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.552795, accuracy: 0.660000\n",
            "iter: 16, logloss: 0.515441, accuracy: 0.660000\n",
            "iter: 16, logloss: 0.571427, accuracy: 0.659800\n",
            "iter: 16, logloss: 0.551604, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.513627, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.569000, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.550464, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.511896, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.566685, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.549376, accuracy: 0.659800\n",
            "iter: 19, logloss: 0.510242, accuracy: 0.660000\n",
            "iter: 19, logloss: 0.564475, accuracy: 0.660000\n",
            "iter: 19, logloss: 0.548332, accuracy: 0.660000\n",
            "iter: 20, logloss: 0.508666, accuracy: 0.659800\n",
            "iter: 20, logloss: 0.562363, accuracy: 0.660000\n",
            "iter: 20, logloss: 0.547332, accuracy: 0.660000\n",
            "iter: 21, logloss: 0.507157, accuracy: 0.660000\n",
            "iter: 21, logloss: 0.560347, accuracy: 0.659600\n",
            "iter: 21, logloss: 0.546377, accuracy: 0.660000\n",
            "iter: 22, logloss: 0.505718, accuracy: 0.660000\n",
            "iter: 22, logloss: 0.558418, accuracy: 0.659800\n",
            "iter: 22, logloss: 0.545460, accuracy: 0.660000\n",
            "iter: 23, logloss: 0.504343, accuracy: 0.660000\n",
            "iter: 23, logloss: 0.556573, accuracy: 0.659800\n",
            "iter: 23, logloss: 0.544582, accuracy: 0.660000\n",
            "iter: 24, logloss: 0.503029, accuracy: 0.660000\n",
            "iter: 24, logloss: 0.554806, accuracy: 0.659600\n",
            "iter: 24, logloss: 0.543740, accuracy: 0.659600\n",
            "iter: 25, logloss: 0.501773, accuracy: 0.660000\n",
            "iter: 25, logloss: 0.553113, accuracy: 0.659600\n",
            "iter: 25, logloss: 0.542931, accuracy: 0.659800\n",
            "iter: 26, logloss: 0.500571, accuracy: 0.659800\n",
            "iter: 26, logloss: 0.551489, accuracy: 0.660000\n",
            "iter: 26, logloss: 0.542156, accuracy: 0.659800\n",
            "iter: 27, logloss: 0.499420, accuracy: 0.659600\n",
            "iter: 27, logloss: 0.549930, accuracy: 0.660000\n",
            "iter: 27, logloss: 0.541412, accuracy: 0.659600\n",
            "iter: 28, logloss: 0.498319, accuracy: 0.659800\n",
            "iter: 28, logloss: 0.548433, accuracy: 0.660000\n",
            "iter: 28, logloss: 0.540697, accuracy: 0.659600\n",
            "iter: 29, logloss: 0.497265, accuracy: 0.659800\n",
            "iter: 29, logloss: 0.546995, accuracy: 0.659600\n",
            "iter: 29, logloss: 0.540010, accuracy: 0.659800\n",
            "iter: 30, logloss: 0.496253, accuracy: 0.659600\n",
            "iter: 30, logloss: 0.545611, accuracy: 0.659600\n",
            "iter: 30, logloss: 0.539350, accuracy: 0.660000\n",
            "iter: 31, logloss: 0.495284, accuracy: 0.659600\n",
            "iter: 31, logloss: 0.544279, accuracy: 0.659600\n",
            "iter: 31, logloss: 0.538716, accuracy: 0.660000\n",
            "iter: 32, logloss: 0.494354, accuracy: 0.659600\n",
            "iter: 32, logloss: 0.542998, accuracy: 0.660000\n",
            "iter: 32, logloss: 0.538106, accuracy: 0.660000\n",
            "iter: 33, logloss: 0.493461, accuracy: 0.659800\n",
            "iter: 33, logloss: 0.541761, accuracy: 0.659800\n",
            "iter: 33, logloss: 0.537518, accuracy: 0.660000\n",
            "iter: 34, logloss: 0.492603, accuracy: 0.660000\n",
            "iter: 34, logloss: 0.540569, accuracy: 0.659800\n",
            "iter: 34, logloss: 0.536952, accuracy: 0.659800\n",
            "iter: 35, logloss: 0.491778, accuracy: 0.660000\n",
            "iter: 35, logloss: 0.539418, accuracy: 0.660000\n",
            "iter: 35, logloss: 0.536407, accuracy: 0.659600\n",
            "iter: 36, logloss: 0.490984, accuracy: 0.660000\n",
            "iter: 36, logloss: 0.538309, accuracy: 0.660000\n",
            "iter: 36, logloss: 0.535883, accuracy: 0.659800\n",
            "iter: 37, logloss: 0.490221, accuracy: 0.660000\n",
            "iter: 37, logloss: 0.537237, accuracy: 0.659800\n",
            "iter: 37, logloss: 0.535377, accuracy: 0.659800\n",
            "iter: 38, logloss: 0.489485, accuracy: 0.660000\n",
            "iter: 38, logloss: 0.536200, accuracy: 0.660000\n",
            "iter: 38, logloss: 0.534888, accuracy: 0.660000\n",
            "iter: 39, logloss: 0.488777, accuracy: 0.659800\n",
            "iter: 39, logloss: 0.535198, accuracy: 0.659800\n",
            "iter: 39, logloss: 0.534417, accuracy: 0.659800\n",
            "iter: 40, logloss: 0.488094, accuracy: 0.659600\n",
            "iter: 40, logloss: 0.534229, accuracy: 0.660200\n",
            "iter: 40, logloss: 0.533962, accuracy: 0.659800\n",
            "iter: 41, logloss: 0.487435, accuracy: 0.659800\n",
            "iter: 41, logloss: 0.533290, accuracy: 0.660200\n",
            "iter: 41, logloss: 0.533523, accuracy: 0.659800\n",
            "iter: 42, logloss: 0.486798, accuracy: 0.659800\n",
            "iter: 42, logloss: 0.532383, accuracy: 0.660000\n",
            "iter: 42, logloss: 0.533099, accuracy: 0.660000\n",
            "iter: 43, logloss: 0.486185, accuracy: 0.659800\n",
            "iter: 43, logloss: 0.531502, accuracy: 0.660000\n",
            "iter: 43, logloss: 0.532689, accuracy: 0.660000\n",
            "iter: 44, logloss: 0.485590, accuracy: 0.660000\n",
            "iter: 44, logloss: 0.530650, accuracy: 0.659600\n",
            "iter: 44, logloss: 0.532293, accuracy: 0.660000\n",
            "iter: 45, logloss: 0.485017, accuracy: 0.659800\n",
            "iter: 45, logloss: 0.529824, accuracy: 0.659800\n",
            "iter: 45, logloss: 0.531908, accuracy: 0.659800\n",
            "iter: 46, logloss: 0.484462, accuracy: 0.659800\n",
            "iter: 46, logloss: 0.529023, accuracy: 0.660200\n",
            "iter: 46, logloss: 0.531537, accuracy: 0.660000\n",
            "iter: 47, logloss: 0.483924, accuracy: 0.659800\n",
            "iter: 47, logloss: 0.528246, accuracy: 0.660000\n",
            "iter: 47, logloss: 0.531177, accuracy: 0.659800\n",
            "iter: 48, logloss: 0.483405, accuracy: 0.660200\n",
            "iter: 48, logloss: 0.527492, accuracy: 0.660000\n",
            "iter: 48, logloss: 0.530828, accuracy: 0.660000\n",
            "iter: 49, logloss: 0.482901, accuracy: 0.660000\n",
            "iter: 49, logloss: 0.526760, accuracy: 0.659800\n",
            "iter: 49, logloss: 0.530491, accuracy: 0.660200\n",
            "iter: 50, logloss: 0.482413, accuracy: 0.660000\n",
            "iter: 50, logloss: 0.526048, accuracy: 0.660400\n",
            "iter: 50, logloss: 0.530164, accuracy: 0.660200\n",
            "iter: 51, logloss: 0.481939, accuracy: 0.660000\n",
            "iter: 51, logloss: 0.525358, accuracy: 0.660400\n",
            "iter: 51, logloss: 0.529846, accuracy: 0.660200\n",
            "iter: 52, logloss: 0.481481, accuracy: 0.659800\n",
            "iter: 52, logloss: 0.524688, accuracy: 0.660600\n",
            "iter: 52, logloss: 0.529538, accuracy: 0.660000\n",
            "iter: 53, logloss: 0.481035, accuracy: 0.659800\n",
            "iter: 53, logloss: 0.524036, accuracy: 0.660800\n",
            "iter: 53, logloss: 0.529240, accuracy: 0.660000\n",
            "iter: 54, logloss: 0.480604, accuracy: 0.659800\n",
            "iter: 54, logloss: 0.523403, accuracy: 0.660800\n",
            "iter: 54, logloss: 0.528950, accuracy: 0.659800\n",
            "iter: 55, logloss: 0.480183, accuracy: 0.659800\n",
            "iter: 55, logloss: 0.522787, accuracy: 0.661400\n",
            "iter: 55, logloss: 0.528668, accuracy: 0.659600\n",
            "iter: 56, logloss: 0.479776, accuracy: 0.659800\n",
            "iter: 56, logloss: 0.522187, accuracy: 0.661600\n",
            "iter: 56, logloss: 0.528394, accuracy: 0.660000\n",
            "iter: 57, logloss: 0.479380, accuracy: 0.660000\n",
            "iter: 57, logloss: 0.521604, accuracy: 0.661800\n",
            "iter: 57, logloss: 0.528129, accuracy: 0.660000\n",
            "iter: 58, logloss: 0.478995, accuracy: 0.660200\n",
            "iter: 58, logloss: 0.521038, accuracy: 0.662200\n",
            "iter: 58, logloss: 0.527869, accuracy: 0.660200\n",
            "iter: 59, logloss: 0.478621, accuracy: 0.660200\n",
            "iter: 59, logloss: 0.520486, accuracy: 0.662600\n",
            "iter: 59, logloss: 0.527617, accuracy: 0.660200\n",
            "iter: 60, logloss: 0.478256, accuracy: 0.660200\n",
            "iter: 60, logloss: 0.519948, accuracy: 0.663200\n",
            "iter: 60, logloss: 0.527372, accuracy: 0.660000\n",
            "iter: 61, logloss: 0.477902, accuracy: 0.660200\n",
            "iter: 61, logloss: 0.519424, accuracy: 0.663000\n",
            "iter: 61, logloss: 0.527133, accuracy: 0.660000\n",
            "iter: 62, logloss: 0.477557, accuracy: 0.660000\n",
            "iter: 62, logloss: 0.518915, accuracy: 0.663200\n",
            "iter: 62, logloss: 0.526901, accuracy: 0.659800\n",
            "iter: 63, logloss: 0.477220, accuracy: 0.660000\n",
            "iter: 63, logloss: 0.518419, accuracy: 0.663200\n",
            "iter: 63, logloss: 0.526676, accuracy: 0.660000\n",
            "iter: 64, logloss: 0.476894, accuracy: 0.659800\n",
            "iter: 64, logloss: 0.517935, accuracy: 0.663800\n",
            "iter: 64, logloss: 0.526456, accuracy: 0.660000\n",
            "iter: 65, logloss: 0.476574, accuracy: 0.659600\n",
            "iter: 65, logloss: 0.517464, accuracy: 0.664600\n",
            "iter: 65, logloss: 0.526241, accuracy: 0.660400\n",
            "iter: 66, logloss: 0.476263, accuracy: 0.659800\n",
            "iter: 66, logloss: 0.517003, accuracy: 0.665000\n",
            "iter: 66, logloss: 0.526031, accuracy: 0.660400\n",
            "iter: 67, logloss: 0.475961, accuracy: 0.660000\n",
            "iter: 67, logloss: 0.516556, accuracy: 0.665800\n",
            "iter: 67, logloss: 0.525828, accuracy: 0.660600\n",
            "iter: 68, logloss: 0.475663, accuracy: 0.660000\n",
            "iter: 68, logloss: 0.516118, accuracy: 0.667000\n",
            "iter: 68, logloss: 0.525627, accuracy: 0.660800\n",
            "iter: 69, logloss: 0.475376, accuracy: 0.660000\n",
            "iter: 69, logloss: 0.515692, accuracy: 0.667400\n",
            "iter: 69, logloss: 0.525434, accuracy: 0.660800\n",
            "iter: 70, logloss: 0.475093, accuracy: 0.660200\n",
            "iter: 70, logloss: 0.515276, accuracy: 0.667800\n",
            "iter: 70, logloss: 0.525245, accuracy: 0.661000\n",
            "iter: 71, logloss: 0.474820, accuracy: 0.660200\n",
            "iter: 71, logloss: 0.514870, accuracy: 0.667800\n",
            "iter: 71, logloss: 0.525060, accuracy: 0.661000\n",
            "iter: 72, logloss: 0.474551, accuracy: 0.660200\n",
            "iter: 72, logloss: 0.514475, accuracy: 0.668200\n",
            "iter: 72, logloss: 0.524879, accuracy: 0.661400\n",
            "iter: 73, logloss: 0.474288, accuracy: 0.660200\n",
            "iter: 73, logloss: 0.514088, accuracy: 0.668200\n",
            "iter: 73, logloss: 0.524702, accuracy: 0.662000\n",
            "iter: 74, logloss: 0.474032, accuracy: 0.660000\n",
            "iter: 74, logloss: 0.513711, accuracy: 0.668600\n",
            "iter: 74, logloss: 0.524530, accuracy: 0.662600\n",
            "iter: 75, logloss: 0.473783, accuracy: 0.659800\n",
            "iter: 75, logloss: 0.513342, accuracy: 0.669800\n",
            "iter: 75, logloss: 0.524360, accuracy: 0.662200\n",
            "iter: 76, logloss: 0.473537, accuracy: 0.660000\n",
            "iter: 76, logloss: 0.512983, accuracy: 0.670400\n",
            "iter: 76, logloss: 0.524196, accuracy: 0.662000\n",
            "iter: 77, logloss: 0.473299, accuracy: 0.660000\n",
            "iter: 77, logloss: 0.512631, accuracy: 0.670600\n",
            "iter: 77, logloss: 0.524034, accuracy: 0.662600\n",
            "iter: 78, logloss: 0.473064, accuracy: 0.659800\n",
            "iter: 78, logloss: 0.512287, accuracy: 0.670400\n",
            "iter: 78, logloss: 0.523876, accuracy: 0.662800\n",
            "iter: 79, logloss: 0.472835, accuracy: 0.660200\n",
            "iter: 79, logloss: 0.511953, accuracy: 0.669600\n",
            "iter: 79, logloss: 0.523723, accuracy: 0.663400\n",
            "iter: 80, logloss: 0.472612, accuracy: 0.660200\n",
            "iter: 80, logloss: 0.511625, accuracy: 0.669800\n",
            "iter: 80, logloss: 0.523571, accuracy: 0.663200\n",
            "iter: 81, logloss: 0.472393, accuracy: 0.660200\n",
            "iter: 81, logloss: 0.511304, accuracy: 0.669800\n",
            "iter: 81, logloss: 0.523423, accuracy: 0.663400\n",
            "iter: 82, logloss: 0.472179, accuracy: 0.660400\n",
            "iter: 82, logloss: 0.510991, accuracy: 0.670200\n",
            "iter: 82, logloss: 0.523277, accuracy: 0.663200\n",
            "iter: 83, logloss: 0.471968, accuracy: 0.660400\n",
            "iter: 83, logloss: 0.510685, accuracy: 0.670400\n",
            "iter: 83, logloss: 0.523136, accuracy: 0.663600\n",
            "iter: 84, logloss: 0.471763, accuracy: 0.660800\n",
            "iter: 84, logloss: 0.510385, accuracy: 0.670800\n",
            "iter: 84, logloss: 0.522996, accuracy: 0.663600\n",
            "iter: 85, logloss: 0.471561, accuracy: 0.660800\n",
            "iter: 85, logloss: 0.510093, accuracy: 0.670400\n",
            "iter: 85, logloss: 0.522859, accuracy: 0.663800\n",
            "iter: 86, logloss: 0.471364, accuracy: 0.661000\n",
            "iter: 86, logloss: 0.509806, accuracy: 0.670600\n",
            "iter: 86, logloss: 0.522726, accuracy: 0.664200\n",
            "iter: 87, logloss: 0.471171, accuracy: 0.661200\n",
            "iter: 87, logloss: 0.509526, accuracy: 0.671000\n",
            "iter: 87, logloss: 0.522595, accuracy: 0.664400\n",
            "iter: 88, logloss: 0.470980, accuracy: 0.661200\n",
            "iter: 88, logloss: 0.509251, accuracy: 0.671400\n",
            "iter: 88, logloss: 0.522466, accuracy: 0.664800\n",
            "iter: 89, logloss: 0.470795, accuracy: 0.661400\n",
            "iter: 89, logloss: 0.508983, accuracy: 0.671400\n",
            "iter: 89, logloss: 0.522340, accuracy: 0.665200\n",
            "iter: 90, logloss: 0.470612, accuracy: 0.661800\n",
            "iter: 90, logloss: 0.508720, accuracy: 0.671800\n",
            "iter: 90, logloss: 0.522215, accuracy: 0.665600\n",
            "iter: 91, logloss: 0.470434, accuracy: 0.661800\n",
            "iter: 91, logloss: 0.508464, accuracy: 0.672200\n",
            "iter: 91, logloss: 0.522094, accuracy: 0.666600\n",
            "iter: 92, logloss: 0.470259, accuracy: 0.662400\n",
            "iter: 92, logloss: 0.508212, accuracy: 0.672800\n",
            "iter: 92, logloss: 0.521975, accuracy: 0.666600\n",
            "iter: 93, logloss: 0.470085, accuracy: 0.662600\n",
            "iter: 93, logloss: 0.507966, accuracy: 0.673200\n",
            "iter: 93, logloss: 0.521857, accuracy: 0.667400\n",
            "iter: 94, logloss: 0.469917, accuracy: 0.662200\n",
            "iter: 94, logloss: 0.507724, accuracy: 0.673200\n",
            "iter: 94, logloss: 0.521742, accuracy: 0.668000\n",
            "iter: 95, logloss: 0.469750, accuracy: 0.662400\n",
            "iter: 95, logloss: 0.507488, accuracy: 0.673400\n",
            "iter: 95, logloss: 0.521627, accuracy: 0.668000\n",
            "iter: 96, logloss: 0.469587, accuracy: 0.662400\n",
            "iter: 96, logloss: 0.507256, accuracy: 0.673800\n",
            "iter: 96, logloss: 0.521517, accuracy: 0.668000\n",
            "iter: 97, logloss: 0.469427, accuracy: 0.662800\n",
            "iter: 97, logloss: 0.507030, accuracy: 0.674200\n",
            "iter: 97, logloss: 0.521407, accuracy: 0.667800\n",
            "iter: 98, logloss: 0.469271, accuracy: 0.662800\n",
            "iter: 98, logloss: 0.506808, accuracy: 0.674400\n",
            "iter: 98, logloss: 0.521300, accuracy: 0.668000\n",
            "iter: 99, logloss: 0.469115, accuracy: 0.663000\n",
            "iter: 99, logloss: 0.506590, accuracy: 0.674600\n",
            "iter: 99, logloss: 0.521192, accuracy: 0.668200\n",
            "Duration (s): 0.366922\n",
            "final accuracy: 0.668200\n",
            "final weights: \n",
            "[\n",
            "0.000203,\t-0.000061;\n",
            "0.000442,\t-0.000091;\n",
            "0.000164,\t-0.000098;\n",
            "-0.000158,\t0.000220;\n",
            "0.000312,\t-0.000414;\n",
            "-0.000209,\t0.000273;\n",
            "-0.000982,\t0.000909;\n",
            "0.000217,\t0.000307;\n",
            "0.000084,\t0.000129\n",
            "]\n",
            "CPU times: user 10.2 ms, sys: 4.74 ms, total: 15 ms\n",
            "Wall time: 1.02 s\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%%time\n",
        "!./a.out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "kR2kCNEIlpqQ",
        "outputId": "bd5b18b5-822d-48b1-c2cd-ed2b045881b9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "Compile with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcfLGo1UrMq9",
        "outputId": "0470bb9e-2ff9-43ba-9817-3195c8b652e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_classification.cu(80): warning: variable \"periods\" was declared but never referenced\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvcc -g -G -I /usr/local/cuda/samples/common/inc/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu  read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ8nAtzGTRgH",
        "outputId": "2cc95523-150e-4dcf-e4cb-a19f36c3bb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[tcsetpgrp failed in terminal_inferior: Inappropriate ioctl for device]\n",
            "[tcsetpgrp failed in terminal_inferior: Inappropriate ioctl for device]\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[tcsetpgrp failed in terminal_inferior: Inappropriate ioctl for device]\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t-114.58\t-114.59\t-114.59\t-114.6\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t33.61\t34.83\t33.61\t34.83\t\n",
            "15\t19\t17\t14\t20\t29\t25\t41\t34\t46\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t2907\t812\t4789\t1497\t\n",
            "1283\t1901\t174\t337\t326\t236\t680\t168\t1175\t309\t\n",
            "1015\t1129\t333\t515\t624\t671\t1841\t375\t3134\t787\t\n",
            "472\t463\t117\t226\t262\t239\t633\t158\t1056\t271\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t2.6768\t1.7083\t2.1782\t2.1908\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "[tcsetpgrp failed in terminal_inferior: Inappropriate ioctl for device]\n",
            "[New Thread 0x7fba78664700 (LWP 7434)]\n",
            "[New Thread 0x7fba77e63700 (LWP 7435)]\n",
            "[tcsetpgrp failed in terminal_inferior: Inappropriate ioctl for device]\n",
            "initial accuracy: 0.660200\n",
            "iter: 0, logloss: 0.573496, accuracy: 0.660000\n",
            "iter: 0, logloss: 0.629248, accuracy: 0.660200\n",
            "iter: 0, logloss: 0.583235, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.556888, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.625339, accuracy: 0.660400\n",
            "iter: 1, logloss: 0.577853, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.552306, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.621040, accuracy: 0.660400\n",
            "iter: 2, logloss: 0.574950, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.548659, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.616440, accuracy: 0.660400\n",
            "iter: 3, logloss: 0.572572, accuracy: 0.660400\n",
            "iter: 4, logloss: 0.545293, accuracy: 0.660200\n",
            "iter: 4, logloss: 0.611906, accuracy: 0.660400\n",
            "iter: 4, logloss: 0.570405, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.542107, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.607553, accuracy: 0.660000\n",
            "iter: 5, logloss: 0.568372, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.539075, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.603399, accuracy: 0.660000\n",
            "iter: 6, logloss: 0.566449, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.536184, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.599448, accuracy: 0.660000\n",
            "iter: 7, logloss: 0.564620, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.533427, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.595688, accuracy: 0.660000\n",
            "iter: 8, logloss: 0.562881, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.530795, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.592110, accuracy: 0.660000\n",
            "iter: 9, logloss: 0.561225, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.528283, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.588706, accuracy: 0.660000\n",
            "iter: 10, logloss: 0.559651, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.525887, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.585465, accuracy: 0.660000\n",
            "iter: 11, logloss: 0.558147, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.523599, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.582378, accuracy: 0.660000\n",
            "iter: 12, logloss: 0.556714, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.521414, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.579440, accuracy: 0.660000\n",
            "iter: 13, logloss: 0.555348, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.519329, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.576639, accuracy: 0.660000\n",
            "iter: 14, logloss: 0.554043, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.517339, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.573971, accuracy: 0.660000\n",
            "iter: 15, logloss: 0.552795, accuracy: 0.660000\n",
            "iter: 16, logloss: 0.515441, accuracy: 0.660000\n",
            "iter: 16, logloss: 0.571427, accuracy: 0.659800\n",
            "iter: 16, logloss: 0.551604, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.513627, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.569000, accuracy: 0.660000\n",
            "iter: 17, logloss: 0.550464, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.511896, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.566685, accuracy: 0.660000\n",
            "iter: 18, logloss: 0.549376, accuracy: 0.659800\n",
            "iter: 19, logloss: 0.510242, accuracy: 0.660000\n",
            "iter: 19, logloss: 0.564475, accuracy: 0.660000\n",
            "iter: 19, logloss: 0.548332, accuracy: 0.660000\n",
            "iter: 20, logloss: 0.508666, accuracy: 0.659800\n",
            "iter: 20, logloss: 0.562363, accuracy: 0.660000\n",
            "iter: 20, logloss: 0.547332, accuracy: 0.660000\n",
            "iter: 21, logloss: 0.507157, accuracy: 0.660000\n",
            "iter: 21, logloss: 0.560347, accuracy: 0.659600\n",
            "iter: 21, logloss: 0.546377, accuracy: 0.660000\n",
            "iter: 22, logloss: 0.505718, accuracy: 0.660000\n",
            "iter: 22, logloss: 0.558418, accuracy: 0.659800\n",
            "iter: 22, logloss: 0.545460, accuracy: 0.660000\n",
            "iter: 23, logloss: 0.504343, accuracy: 0.660000\n",
            "iter: 23, logloss: 0.556573, accuracy: 0.659800\n",
            "iter: 23, logloss: 0.544582, accuracy: 0.660000\n",
            "iter: 24, logloss: 0.503029, accuracy: 0.660000\n",
            "iter: 24, logloss: 0.554806, accuracy: 0.659600\n",
            "iter: 24, logloss: 0.543740, accuracy: 0.659600\n",
            "iter: 25, logloss: 0.501773, accuracy: 0.660000\n",
            "iter: 25, logloss: 0.553113, accuracy: 0.659600\n",
            "iter: 25, logloss: 0.542931, accuracy: 0.659800\n",
            "iter: 26, logloss: 0.500571, accuracy: 0.659800\n",
            "iter: 26, logloss: 0.551489, accuracy: 0.660000\n",
            "iter: 26, logloss: 0.542156, accuracy: 0.659800\n",
            "iter: 27, logloss: 0.499420, accuracy: 0.659600\n",
            "iter: 27, logloss: 0.549930, accuracy: 0.660000\n",
            "iter: 27, logloss: 0.541412, accuracy: 0.659600\n",
            "iter: 28, logloss: 0.498319, accuracy: 0.659800\n",
            "iter: 28, logloss: 0.548433, accuracy: 0.660000\n",
            "iter: 28, logloss: 0.540697, accuracy: 0.659600\n",
            "iter: 29, logloss: 0.497265, accuracy: 0.659800\n",
            "iter: 29, logloss: 0.546995, accuracy: 0.659600\n",
            "iter: 29, logloss: 0.540010, accuracy: 0.659800\n",
            "iter: 30, logloss: 0.496253, accuracy: 0.659600\n",
            "iter: 30, logloss: 0.545611, accuracy: 0.659600\n",
            "iter: 30, logloss: 0.539350, accuracy: 0.660000\n",
            "iter: 31, logloss: 0.495284, accuracy: 0.659600\n",
            "iter: 31, logloss: 0.544279, accuracy: 0.659600\n",
            "iter: 31, logloss: 0.538716, accuracy: 0.660000\n",
            "iter: 32, logloss: 0.494354, accuracy: 0.659600\n",
            "iter: 32, logloss: 0.542998, accuracy: 0.660000\n",
            "iter: 32, logloss: 0.538106, accuracy: 0.660000\n",
            "iter: 33, logloss: 0.493461, accuracy: 0.659800\n",
            "iter: 33, logloss: 0.541761, accuracy: 0.659800\n",
            "iter: 33, logloss: 0.537518, accuracy: 0.660000\n",
            "iter: 34, logloss: 0.492603, accuracy: 0.660000\n",
            "iter: 34, logloss: 0.540569, accuracy: 0.659800\n",
            "iter: 34, logloss: 0.536952, accuracy: 0.659800\n",
            "iter: 35, logloss: 0.491778, accuracy: 0.660000\n",
            "iter: 35, logloss: 0.539418, accuracy: 0.660000\n",
            "iter: 35, logloss: 0.536407, accuracy: 0.659600\n",
            "iter: 36, logloss: 0.490984, accuracy: 0.660000\n",
            "iter: 36, logloss: 0.538309, accuracy: 0.660000\n",
            "iter: 36, logloss: 0.535883, accuracy: 0.659800\n",
            "iter: 37, logloss: 0.490221, accuracy: 0.660000\n",
            "iter: 37, logloss: 0.537237, accuracy: 0.659800\n",
            "iter: 37, logloss: 0.535377, accuracy: 0.659800\n",
            "iter: 38, logloss: 0.489485, accuracy: 0.660000\n",
            "iter: 38, logloss: 0.536200, accuracy: 0.660000\n",
            "iter: 38, logloss: 0.534888, accuracy: 0.660000\n",
            "iter: 39, logloss: 0.488777, accuracy: 0.659800\n",
            "iter: 39, logloss: 0.535198, accuracy: 0.659800\n",
            "iter: 39, logloss: 0.534417, accuracy: 0.659800\n",
            "iter: 40, logloss: 0.488094, accuracy: 0.659600\n",
            "iter: 40, logloss: 0.534229, accuracy: 0.660200\n",
            "iter: 40, logloss: 0.533962, accuracy: 0.659800\n",
            "iter: 41, logloss: 0.487435, accuracy: 0.659800\n",
            "iter: 41, logloss: 0.533290, accuracy: 0.660200\n",
            "iter: 41, logloss: 0.533523, accuracy: 0.659800\n",
            "iter: 42, logloss: 0.486798, accuracy: 0.659800\n",
            "iter: 42, logloss: 0.532383, accuracy: 0.660000\n",
            "iter: 42, logloss: 0.533099, accuracy: 0.660000\n",
            "iter: 43, logloss: 0.486185, accuracy: 0.659800\n",
            "iter: 43, logloss: 0.531502, accuracy: 0.660000\n",
            "iter: 43, logloss: 0.532689, accuracy: 0.660000\n",
            "iter: 44, logloss: 0.485590, accuracy: 0.660000\n",
            "iter: 44, logloss: 0.530650, accuracy: 0.659600\n",
            "iter: 44, logloss: 0.532293, accuracy: 0.660000\n"
          ]
        }
      ],
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGJ6uVNBVHUs"
      },
      "outputs": [],
      "source": [
        "!cuda-memcheck ./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44Pk-JL7rAhi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqs64V1tEysf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}